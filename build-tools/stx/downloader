#!/usr/bin/python3

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# Copyright (C) 2021-2022 Wind River Systems,Inc

import apt
import argparse
import debrepack
import discovery
import fnmatch
import logging
import os
import pathlib
import repo_manage
import shutil
import signal
import sys
import utils

DEFAULT_ARCH = 'amd64'
REPO_BIN = 'deb-local-binary'
mirror_root = os.environ.get('STX_MIRROR')
stx_src_mirror = os.path.join(mirror_root, 'sources')
stx_bin_mirror = os.path.join(mirror_root, 'binaries')
all_binary_lists = ['base-bullseye.lst', 'os-std.lst', 'os-rt.lst']
types_pkg_dirs = ['debian_pkg_dirs', 'debian_pkg_dirs_rt', 'debian_pkg_dirs_installer']

logger = logging.getLogger('downloader')
utils.set_logger(logger)

STX_DEFAULT_DISTRO = discovery.STX_DEFAULT_DISTRO

ALL_DISTROS = discovery.get_all_distros()
ALL_LAYERS = discovery.get_all_layers(distro=STX_DEFAULT_DISTRO)
ALL_BUILD_TYPES = discovery.get_all_build_types(distro=STX_DEFAULT_DISTRO)

CENGN_STRATEGY = os.environ.get('CENGN_STRATEGY')

def get_downloaded(dl_dir, dl_type):
    """
    Browse and get the already downloaded binary or source
    packages in dl_dir
        dl_dir: mirror dir
        dl_type: binary or source
        return: list of downloaded targets
    """
    dl_list = []
    if not os.path.exists(dl_dir):
        return []

    if dl_type == 'source':
        logger.debug('debrepack will check the whole source mirror')

    for file in os.listdir(dl_dir):
        if dl_type == 'binary' and file.endswith('.deb'):
            dl_list.append(file)

    return dl_list


def get_pkgs_from_list(root_dir, list_file):
    """
    Read each lines in debian_pkg_dirs_<type> and add it
    to the map, for example:
    entries { 'dhcp': '<path to>/stx/integ/base/dhcp',
              'tsconfig': '<path to>/config/tsconfig'}
    """
    entries = {}
    try:
        with open(list_file, 'r') as flist:
            lines = list(line for line in (p.strip() for p in flist) if line)
    except Exception as e:
        logger.error(str(e))
    else:
        for entry in lines:
            entry = entry.strip()
            if entry.startswith('#'):
                continue
            entries[os.path.basename(entry)] = os.path.join(root_dir, entry)
    return entries


def get_all_stx_pkgs():
    """
    Scan all STX source layers to get all buildable packages
    Params: None
    Return:
        Map of all STX buildable packages and path to debian folder
    """
    pkgs = {}
    projects_root = os.environ.get('MY_REPO')
    for root, dirs, files in os.walk(projects_root):
        if dirs:
            pass
        for r in files:
            # Find all types of package dirs?
            if r in types_pkg_dirs:
                pkgs_file = os.path.join(root, r)
                pkgs.update(get_pkgs_from_list(root, pkgs_file))
    return pkgs


def get_all_binary_list(distro=STX_DEFAULT_DISTRO, layers=None, build_types=None):
    """
    Return all binary packages listed in base-bullseye.lst, os-std.lst,os-rt.lst
    """
    layer_binaries = {}
    stx_config = os.path.join(os.environ.get('MY_REPO_ROOT_DIR'),
                              'stx-tools/debian-mirror-tools/config/debian')

    if layers:
        for layer in layers:
            if layer not in ALL_LAYERS:
                logger.error(' '.join([layer, 'is not a valid layer']))
                return
    else:
        layers = ALL_LAYERS

    for layer in layers:
        if layer not in layer_binaries:
            layer_binaries[layer] = []
        search_dir = os.path.join(stx_config, layer)
        all_build_types = discovery.get_layer_build_types(distro=distro, layer=layer)
        if not all_build_types:
            logger.error(' '.join(['No build_types found for distro', distro, 'layer', layer]))
            return

        if not build_types:
            build_types = all_build_types

        for build_type in build_types:
            if build_type not in all_build_types:
                logger.warning(' '.join([build_type, 'is not a valid build_type for distro', distro, 'of layer', layer]))
                continue

            pattern=''.join(['os-',build_type,'.lst'])
            for root, dirs, files in os.walk(search_dir):
                for f in fnmatch.filter(files, pattern):
                    layer_binaries[layer].append(os.path.join(root, f))
        logger.info(
            f"Binary lists for layer `{layer}`: "
            f"{layer_binaries[layer]}"
        )

    search_dir = os.path.join(stx_config, 'common')
    pattern='base-*.lst'

    if "common" not in layer_binaries:
        layer_binaries["common"] = []

    for root, dirs, files in os.walk(search_dir):
        for f in fnmatch.filter(files, pattern):
            layer_binaries["common"].append(os.path.join(root, f))

    logger.info(
        f"Binary lists for layer `common`: "
        f"{layer_binaries['common']}"
    )
    return layer_binaries


class BaseDownloader():
    def __init__(self, arch, _dl_dir, clean):
        self.dl_dir = _dl_dir
        self.arch = arch
        self.clean_mirror = clean
        self.dl_need = []
        self.dl_success = []
        self.dl_failed = []
        rlogger = logging.getLogger('repo_manager')
        utils.set_logger(rlogger)
        self.repomgr = repo_manage.RepoMgr('aptly', os.environ.get('REPOMGR_URL'),
                                           '/tmp/', os.environ.get('REPOMGR_ORIGIN'),
                                           rlogger)

    def clean(self):
        if os.path.exists(self.dl_dir):
            if self.clean_mirror:
                try:
                    shutil.rmtree(self.dl_dir)
                except Exception as e:
                    logger.error(str(e))
                    logger.critical("Failed to clean mirror %s", self.dl_dir)
                    sys.exit(1)
                else:
                    logger.debug("Successfully cleaned mirror %s", self.dl_dir)
        os.makedirs(self.dl_dir, exist_ok=True)

    def reports(self):
        ret = 0
        if len(self.dl_need):
            logger.info("++++++++++++++++++++++++++++++++++++++++++++++++++")
            logger.info("Total number of packages needing to be downloaded: %d", len(self.dl_need))

        if len(self.dl_success):
            logger.info("++++++++++++++++++++++++++++++++++++++++++++++++++")
            logger.info("Successfully downloaded packages: %d", len(self.dl_success))
            for dlobj in sorted(self.dl_success):
                logger.info(' '.join(['-', dlobj.strip()]))

        failed_list = list(set(self.dl_need) - set(self.dl_success))
        if len(failed_list):
            logger.error("+++++++++++++++++++++++++++++++++++++++++++++++++")
            logger.error("Failed to download packages: %d", len(failed_list))
            ret = 1
            for dlobj in sorted(failed_list):
                logger.error(' '.join([dlobj.strip()]))
        return ret

    def list_failed_pkgs(self):
        failed_list = list(set(self.dl_need) - set(self.dl_success))
        if len(failed_list):
            logger.error("Packages failed to download:")
            for dlobj in sorted(failed_list):
                logger.error(' '.join([dlobj.strip()]))



class DebDownloader(BaseDownloader):
    def __init__(self, arch, _dl_dir, force, _layer_binaries):
        super(DebDownloader, self).__init__(arch, _dl_dir, force)
        self.need_download = []
        self.downloaded = []
        self.need_upload = []
        self.layer_binaries = _layer_binaries
        self.apt_cache = apt.cache.Cache()

    def _get_layer_binaries_repository(self, layer: str):
        repo = REPO_BIN
        if layer != "common":
            repo = f"{REPO_BIN}-{layer.lower()}"
        return repo

    def create_binary_repo(self):
        if not self.repomgr:
            logger.error("The repo manager is not created")
            return False

        for layer in self.layer_binaries:
            repo = self._get_layer_binaries_repository(layer)
            try:
                self.repomgr.upload_pkg(repo, None)
            except Exception as e:
                logger.error(str(e))
                logger.error("Failed to create repository %s", repo)
                return False

            logger.info("Successfully created repository %s", repo)
        return True

    def download(self, _name, _version, url=None, retries=3):
        if url != None:
            # The "+" in url is converted to "%2B", so convert
            # it back to "+" in save file.
            dl_file = os.path.basename(url).replace("%2B", "+")
            ret = os.path.join(self.dl_dir, dl_file)
            tmp_file = ".".join([ret, "tmp"])
            utils.run_shell_cmd(["rm", "-rf", tmp_file], logger)
            (dl_url, alt_dl_url) = utils.get_download_url(url, CENGN_STRATEGY)
            for i in range(1,retries+1):
                if alt_dl_url:
                    try:
                        utils.run_shell_cmd(["curl", "-k", "-L", "-f", dl_url, "-o", tmp_file], logger)
                    except:
                        if i < retries:
                            try:
                                utils.run_shell_cmd(["curl", "-k", "-L", "-f", alt_dl_url, "-o", tmp_file], logger)
                                break
                            except Exception as e:
                                logger.error(str(e))
                        else:
                            utils.run_shell_cmd(["curl", "-k", "-L", "-f", alt_dl_url, "-o", tmp_file], logger)
                            break
                else:
                    if i < retries:
                        try:
                            utils.run_shell_cmd(["curl", "-k", "-L", "-f", dl_url, "-o", tmp_file], logger)
                            break
                        except Exception as e:
                            logger.error(str(e))
                    else:
                        utils.run_shell_cmd(["curl", "-k", "-L", "-f", dl_url, "-o", tmp_file], logger)
                        break
            utils.run_shell_cmd(["mv", tmp_file, ret], logger)
            return ret

        try:
            package = self.apt_cache[_name]
            candidate = package.versions.get(_version)
            if not candidate:
                logger.error(' '.join(['Fail to download', _name,
                             'with wrong version', _version, '?']))
                logger.error('May need to update the package list file')
                logger.error('package: %s', str(package))
                logger.error('package.versions: %s', str(package.versions))
                return None

            package.candidate = candidate
            ret = package.candidate.fetch_binary(self.dl_dir)
            if ret:
                return ret
        except Exception as e:
            deb_name = _name + '_' + _version
            logger.debug("Fail to fetch binary %s", deb_name)
            logger.debug(str(e))
            '''
            Sometimes the target deb is created in dl_dir, but actually it is
            corrupted file. It should not be uploaded to binary repo.
            '''
            os.system('rm -f ' + os.path.join(self.dl_dir, deb_name + '*.deb'))
        return None


    def reports(self):
        for layer in self.layer_binaries:
            repo = self._get_layer_binaries_repository(layer)
            try:
                self.repomgr.deploy_repo(repo)
            except Exception as e:
                logger.error(str(e))
                logger.error("Failed to publish repository %s", repo)
                return

            if self.layer_binaries[layer]:
                logger.info(f"[{layer}] Binary list:")
                for bin_list in self.layer_binaries[layer]:
                    logger.info(bin_list)

        logger.info("Show result for binary download:")
        return super(DebDownloader, self).reports()

    def download_list_files(self, repo, list_files):
        pkg_data=[]
        if len(list_files):
            for list_file in list_files:
                if not os.path.exists(list_file):
                    continue
                with open(list_file) as flist:
                    lines = list(line for line in (lpkg.strip() for lpkg in flist) if line)
                    for pkg in lines:
                        pkg = pkg.strip()
                        if pkg.startswith('#'):
                            continue
                        pkg_name_array = pkg.split()
                        pkg_name = pkg_name_array[0]
                        if len(pkg_name_array) == 1:
                            logger.error("The package version of %s should be defined in file %s", pkg_name, list_file)
                            logger.error("Please update the list file %s", list_file)
                            sys.exit(1)

                        # strip epoch
                        ver_array = pkg_name_array[1].split(":")
                        if len(ver_array) == 1:
                            pkg_ver = ver_array[0]
                            pkg_epoch = None
                        else:
                            pkg_ver = ver_array[-1]
                            pkg_epoch = ver_array[0]

                        if len(pkg_name_array) == 3:
                            url = pkg_name_array[2]
                            url_dict = utils.deb_file_name_to_dict(os.path.basename(url).replace("%2B", "+"))
                            logger.debug("dkg_data: name=%s, ver=%s, url=%s, url_dict=%s, file=%s", pkg_name, pkg_ver, url,url,  str(url_dict), list_file)
                            if url_dict['ver'] and url_dict['ver'] != pkg_ver:
                                logger.warning("Package version mismatch for package %s, $s vs %s, in file %s", pkg_name, pkg_ver, url_dict['ver'], list_file)
                                pkg_ver = url_dict['ver']
                            if url_dict['epoch'] and url_dict['epoch'] != pkg_epoch:
                                logger.warning("Package epoch mismatch for package %s, $s vs %s, in file %s", pkg_name, pkg_epoch, url_dict['epoch'], list_file)
                                pkg_epoch = url_dict['epoch']
                                
                            # Get arch from filename
                            arch = pathlib.Path(url).stem.split("_")[-1]
                        else:
                            url = None
                            try:
                                package = self.apt_cache[pkg_name]
                            except Exception as e:
                                logger.error(str(e))
                                sys.exit(1)
                            arch = package.candidate.architecture

                        pkg_dict={'name':pkg_name, 'ver':pkg_ver, 'epoch':pkg_epoch, 'arch':arch, 'url':url, 'repo':repo}
                        pkg_data.append(pkg_dict)

        self.download_list(repo, pkg_data)


    def download_list(self, repo, pkg_data):
        logger.info(' '.join(['pkg_data:', str(pkg_data)]))

        # List of packages already downloaded
        self.downloaded = get_downloaded(self.dl_dir, 'binary')
        logger.info(' '.join(['previously downloaded:', str(self.downloaded)]))

        # list of package already uploaded to ANY repo
        previously_uploaded = self.repomgr.list_pkgs(repo)
        logger.info(' '.join(['previously uploaded to repo', repo, ':', str(previously_uploaded)]))

        pkg_data_map = {}
        if pkg_data:
            for pkg_dict in pkg_data:
                pkg_name = pkg_dict['name']
                pkg_ver = pkg_dict['ver']
                pkg_epoch = pkg_dict['epoch']
                arch = pkg_dict['arch']
                url = pkg_dict['url']
                repo = pkg_dict['repo']
                if pkg_name not in pkg_data_map:
                    pkg_data_map[pkg_name] = []
                pkg_data_map[pkg_name].append(pkg_dict)
                pkg_name_ver = '_'.join([pkg_name, pkg_ver])
                if pkg_epoch:
                    pkg_name_epoch_ver = '_'.join([pkg_name, ':'.join([pkg_epoch, pkg_ver])])
                else:
                    pkg_name_epoch_ver = pkg_name_ver

                pname_arch = '_'.join([pkg_name_ver, arch]) + '.deb'
                pname_epoch_arch = '_'.join([pkg_name_epoch_ver, arch]) + '.deb'

                self.dl_need.append(pkg_name_ver)

                if self.downloaded and pname_arch in self.downloaded:
                    logger.debug(''.join([pname_epoch_arch, ' has been downloaded, skip']))
                    self.dl_success.append(pkg_name + '_' + pkg_ver)
                    self.need_upload.append([pname_arch, pname_epoch_arch])
                else:
                    # Tests show that the 'epoch' should be taken when
                    # fetch the package with 'apt' module, there is not 'epoch'
                    # in the dowloaded package name. This also requires the 'epoch'
                    # should be defined in the package list file with ':'
                    self.need_download.append([pname_arch, pkg_name_epoch_ver, url])

        # Download packages
        for debs in self.need_download:
            pname_arch = debs[0]
            pname_epoch_arch = debs[1]
            url = debs[2]
            logger.debug(' '.join(['package', pname_epoch_arch, 'needs to be downloaded']))
            debnames = pname_epoch_arch.split('_')
            deb_name = debnames[0]

            ret = self.download(debnames[0], debnames[1], url)
            if ret:
                deb_ver = debnames[1].split(":")[-1]
                deb_ver_epoch = '_'.join([debnames[0], debnames[1]])
                logger.info(' '.join([deb_ver_epoch, ' download ok']))
                # strip epoch
                self.dl_success.append('_'.join([debnames[0], deb_ver]))
                self.need_upload.append([pname_arch, pname_epoch_arch])
                if previously_uploaded and deb_ver_epoch in previously_uploaded:
                    try:
                        del_ret = self.repomgr.delete_pkg(repo, deb_name, 'binary', deb_ver)
                        logger.debug("deleted the old %s from repo %s, ret %d", deb_name, repo, del_ret)
                    except Exception as e:
                        logger.error(str(e))
                        logger.error("Exception on deleting %s from %s", deb_name, repo)
            else:
                self.dl_failed.append(pname_epoch_arch)

        self.need_download.clear()

        logger.info(' '.join(['need_upload', str(self.need_upload)]))

        # Delete previously uploaded packages that are no longer needed
        for prev_upload in previously_uploaded:
            prev_upload_dict = utils.deb_file_name_to_dict(prev_upload)
            del_name = prev_upload_dict['name']
            delete_me = True 
            # Verify the package is no londer needed    
            if pkg_data_map and del_name in pkg_data_map:
                for needed_dict in pkg_data_map[del_name]:
                    if  prev_upload_dict['ver']   == needed_dict['ver'] and \
                        prev_upload_dict['epoch'] == needed_dict['epoch'] and \
                        prev_upload_dict['arch']  == needed_dict['arch']:
                        # We still need this one
                        delete_me = False
                        continue
            if delete_me:
                del_ver = prev_upload_dict['ver']
                logger.debug("Deleting pkg %s_%s freom %s", del_name, del_ver, repo)
                try:
                    del_ret = self.repomgr.delete_pkg(repo, del_name, 'binary', del_ver)
                except Exception as e:
                    logger.error(str(e))
                    logger.error("Exception on deleting %s from %s", '_'.join([del_name, del_ver]), repo)

        # Upload needed packages
        for debs in self.need_upload:
            deb_ver = debs[0]
            deb_ver_epoch = debs[1]
            deb_path = os.path.join(stx_bin_mirror, deb_ver)
            #  Search the package with the "epoch" in aptly repo
            if previously_uploaded and deb_ver_epoch in previously_uploaded:
                logger.info("%s has already been uploaded to %s, skip", deb_path, repo)
                continue

            deb_needed_dict = utils.deb_file_name_to_dict(deb_ver)
            logger.debug("Uploading pkg %s", deb_path)
            try:
                upload_ret = self.repomgr.upload_pkg(repo, deb_path, deploy=False)
            except Exception as e:
                logger.error(str(e))
                logger.error("Exception on uploading %s to %s", deb_path, repo)
                sys.exit(1)
            else:
                if upload_ret:
                    logger.debug("%s is uploaded to %s", deb_path, repo)
                else:
                    logger.error("Failed to upload %s to %s", deb_path, repo)
                    break

        self.need_upload.clear()


    def start(self):
        """Here define:
        the complete set of binaries = base_bullseye.lst
                                     + <layer>/os-std.lst
                                     + <layer>/os-rt.lst
        """
        super(DebDownloader, self).clean()

        empty = True
        for layer in self.layer_binaries:
            if self.layer_binaries[layer]:
                for bin_list in self.layer_binaries[layer]:
                    empty = False
        if empty:
            logger.error("There are no lists of binary packages found")
            sys.exit(1)

        for layer in self.layer_binaries:
            repo = self._get_layer_binaries_repository(layer)
            if self.layer_binaries[layer]:
                self.download_list_files(repo, self.layer_binaries[layer])


class SrcDownloader(BaseDownloader):
    def __init__(self, arch, _dl_dir, force):
        super(SrcDownloader, self).__init__(arch, _dl_dir, force)
        self.parser = None

    def prepare(self):
        build_dir = os.path.join(os.environ.get('MY_BUILD_PKG_DIR'))
        os.makedirs(build_dir, exist_ok=True)
        recipes_dir = os.path.join(os.environ.get('MY_BUILD_PKG_DIR'), 'recipes')
        os.makedirs(recipes_dir, exist_ok=True)
        if not self.parser:
            try:
                self.parser = debrepack.Parser(build_dir,
                                               recipes_dir, log_level='debug')
            except Exception as e:
                logger.error(str(e))
                logger.error("Failed to create debrepack parser")
                return False

        return True

    def download_pkg_src(self, _pkg_path):
        if not self.parser:
            return False
        try:
            self.parser.download(_pkg_path, self.dl_dir)
        except Exception as e:
            logger.error(str(e))
            logger.error("Failed to download source with %s", _pkg_path)
            return False
        return True

    def download_all(self, distro=STX_DEFAULT_DISTRO, layers=None, build_types=None):
        logger.info("download_all, layers=%s, build_types=%s" % (layers, build_types))
        if layers:
            for layer in layers:
                if layer not in ALL_LAYERS:
                    logger.error(' '.join([layer, 'is not a valid layer']))
                    return
        else:
            layers = ALL_LAYERS

        pkg_dirs = []

        for layer in layers:
            all_build_types = discovery.get_layer_build_types(distro=distro, layer=layer)
            if not all_build_types:
                logger.error(' '.join(['No build_types found for distro', distro, 'layer', layer]))
                return

            if not build_types:
                build_types = all_build_types

            for build_type in build_types:
                if build_type not in all_build_types:
                    logger.warning(' '.join([build_type, 'is not a valid build_type for distro', distro, 'of layer', layer]))
                    continue

                pkg_dirs.extend(discovery.package_dir_list(distro=distro, layer=layer, build_type=build_type))

        if not len(pkg_dirs):
            logger.info("No source packages found")
            return

        pkg_dirs_to_names = discovery.package_dirs_to_names_dict(pkg_dirs, distro=distro)
        for pkg_dir in pkg_dirs_to_names:
            self.dl_need.append(pkg_dirs_to_names[pkg_dir])

        logger.info("Starting to download %d source packages", len(pkg_dirs))
        logger.info("%s", sorted(self.dl_need))
        for pkg_dir in pkg_dirs:
            if self.download_pkg_src(pkg_dir):
                if pkg_dir in pkg_dirs_to_names:
                    self.dl_success.append(pkg_dirs_to_names[pkg_dir])
            else:
                if pkg_dir in pkg_dirs_to_names:
                    self.dl_failed.append(pkg_dirs_to_names[pkg_dir])

    def start(self, distro=STX_DEFAULT_DISTRO, layers=None, build_types=None):
        # stx package source downloading
        super(SrcDownloader, self).clean()

        if self.prepare():
            self.download_all(distro=distro, layers=layers, build_types=build_types)
        else:
            logger.error("Failed to initialize source downloader")
            sys.exit(1)


def dl_signal_handler(signum, frame):
    src_ret = 0
    bin_ret = 0

    logger.info("Received signal of keyboard interrupt")
    if binary_dl:
        bin_ret = binary_dl.reports()
    if source_dl:
        src_ret = source_dl.reports()
    sys.exit(src_ret + bin_ret)


def dl_register_signal_handler():
    signal.signal(signal.SIGINT, dl_signal_handler)
    signal.signal(signal.SIGHUP, dl_signal_handler)
    signal.signal(signal.SIGTERM, dl_signal_handler)


if __name__ == "__main__":
    binary_dl = None
    source_dl = None
    binary_ret = 0
    source_ret = 0
    distro = STX_DEFAULT_DISTRO
    layers = None
    build_types = None

    parser = argparse.ArgumentParser(description="downloader helper")
    parser.add_argument('-b', '--download_binary', help="download binary debs",
                        action='store_true')
    parser.add_argument('-s', '--download_source', help="download stx source",
                        action='store_true')
    parser.add_argument('-c', '--clean_mirror', help="clean the whole mirror and download again, be careful to use",
                        action='store_true')
    parser.add_argument('-d', '--distro', type=str, nargs=1,
                        help="name of the distro to build\n   %s" % ALL_DISTROS,
                        default=STX_DEFAULT_DISTRO, required=False)
    parser.add_argument('-B', '--build-types', type=str,
                        help="comma separated list of all build-types to build\n   %s" % ALL_BUILD_TYPES,
                        default='std,rt', required=False)
    parser.add_argument('-l', '--layers', type=str,
                        help="comma separated list of all layers to build\n   %s" % ALL_LAYERS,
                        default=None, required=False)


    args = parser.parse_args()
    clean_mirror = args.clean_mirror

    if args.distro:
        if args.distro not in ALL_DISTROS:
            logger.error(' '.join(['Distro', args.distro, 'not in', ','.join(ALL_DISTROS)]))
            logger.error("Please consult: downloader --help")
            sys.exit(1)
        distro = args.distro
        ALL_LAYERS = discovery.get_all_layers(distro=distro)
        ALL_BUILD_TYPES = discovery.get_all_build_types(distro=distro)

    if args.build_types:
        build_types = args.build_types.strip().split(',')
        logger.debug("The required types to download:%s", ','.join(build_types))
        for build_type in build_types:
            if build_type not in ALL_BUILD_TYPES:
                logger.error(' '.join(['Build_type', build_type, 'not in', ','.join(ALL_BUILD_TYPES)]))
                logger.error("Please consult: downloader --help")
                sys.exit(1)

    if args.layers:
        layers = args.layers.strip().split(',')
        for layer in layers:
            logger.info("layer=%s" % layer)
            if layer not in ALL_LAYERS:
                logger.error(' '.join(['Layer', layer, 'not in', ','.join(ALL_LAYERS)]))
                logger.error("Please consult: downloader --help")
                sys.exit(1)

    if not args.download_binary and not args.download_source:
        # Default to binary and source when option is not provided
        args.download_binary = True
        args.download_source = True

    if args.download_binary:
        all_binary_lists = get_all_binary_list(distro=distro, layers=layers, build_types=build_types)
        binary_dl = DebDownloader(DEFAULT_ARCH, stx_bin_mirror, clean_mirror, all_binary_lists)
        if not binary_dl.create_binary_repo():
            sys.exit(1)

    if args.download_source:
        source_dl = SrcDownloader(DEFAULT_ARCH, stx_src_mirror, clean_mirror)

    dl_register_signal_handler()
    if binary_dl:
        binary_dl.start()
    if source_dl:
        source_dl.start(distro=distro, layers=layers, build_types=build_types)

    if binary_dl:
        binary_ret = binary_dl.reports()
    if source_dl:
        logger.info('Show the download result for source packages:')
        source_ret = source_dl.reports()

    logger.info("Verifying downloader return status")
    if binary_ret != 0:
        logger.error("Binary downloader failed")
        binary_dl.list_failed_pkgs()
    else:
        logger.info("All binaries were downloaded")

    if source_ret != 0:
        logger.error("Source downloader failed")
        source_dl.list_failed_pkgs()
    else:
        logger.info("All sources were downloaded")

    logger.info("Downloader done")
    sys.exit(binary_ret + source_ret)
